{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abanoubsamir004/berlin-bci-eeg-signal-classification-motor-imagery?scriptVersionId=116463502\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"%pylab inline\nimport numpy as np\nimport scipy.io\nimport warnings\n\n# Suppress the warning\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nfrom sklearn.metrics import accuracy_score\nfrom matplotlib import mlab\nimport matplotlib.pyplot as plt\nimport scipy.signal \nfrom sklearn.model_selection import train_test_split,KFold\nfrom sklearn.linear_model import LogisticRegression\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"m = scipy.io.loadmat(\"BCICIV_calib_ds1g.mat\", struct_as_record=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_rate = m['nfo']['fs'][0][0][0][0]\nEEG = m['cnt'].T\nnchannels, nsamples = EEG.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channel_names = [s[0] for s in m['nfo']['clab'][0][0][0]]\nevent_onsets = m['mrk'][0][0][0]\nevent_codes = m['mrk'][0][0][1]\nlabels = np.zeros((1, nsamples), int)\nlabels[0, event_onsets] = event_codes #put 1 3nd l onsets","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl_lab = [s[0] for s in m['nfo']['classes'][0][0][0]]\ncl1 = cl_lab[0] #left -1\ncl2 = cl_lab[1] #right 1\nnclasses = len(cl_lab)\nnevents = len(event_onsets)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print some information\nprint('Shape of EEG:', EEG.shape)\nprint('Sample rate:', sample_rate)\nprint('Number of channels:', nchannels)\nprint('Channel names:', channel_names)\nprint('Number of events:', event_onsets.shape)\nprint('Event codes:', np.unique(event_codes))\nprint('Class labels:', cl_lab)\nprint('Number of classes:', nclasses)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# Dictionary to store the trials in, each class gets an entry\ntrials = {}\n\nwin = np.arange(int(0.5*sample_rate), int(2.5*sample_rate))\n# Length of the time window\nnsamples = len(win)\n# Loop over the classes (right, left)\nfor cl, code in zip(cl_lab, np.unique(event_codes)):\n    \n    # Extract the onsets for the class\n    cl_onsets = event_onsets[event_codes == code]\n    \n    # Allocate memory for the trials\n    trials[cl] = np.zeros((nchannels, nsamples, len(cl_onsets)))\n    # Extract each trial\n    for i, onset in enumerate(cl_onsets):\n        trials[cl][:,:,i] = EEG[:, win+onset]\n        \n# Some information about the dimensionality of the data (channels x time x trials)\nprint('Shape of trials[cl1]:', trials[cl1].shape)\nprint('Shape of trials[cl2]:', trials[cl2].shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def psd(trials):\n   \n    ntrials = trials.shape[2]\n    trials_PSD = np.zeros((nchannels, 101, ntrials)) #(nsamples/2)+1\n\n    # Iterate over trials and channels\n    for trial in range(ntrials):\n        for ch in range(nchannels):\n            # Calculate the PSD\n            (PSD, freqs) = mlab.psd(trials[ch,:,trial], NFFT=int(nsamples), Fs=sample_rate)\n            trials_PSD[ch, :, trial] = PSD.ravel()\n                \n    return trials_PSD, freqs\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"psd_r, freqs = psd(trials[cl1])\npsd_l, freqs = psd(trials[cl2])\ntrials_PSD = {cl1: psd_r, cl2: psd_l}\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef plot_psd(trials_PSD, freqs, chan_ind, chan_lab=None, maxy=None):\n \n    plt.figure(figsize=(12,5))\n    \n    nchans = len(chan_ind)\n    \n    # Maximum of 3 plots per row\n    nrows = int(np.ceil(nchans / 3))\n    ncols = min(3, nchans)\n    \n    # Enumerate over the channels\n    for i,ch in enumerate(chan_ind):\n        # Figure out which subplot to draw to\n        plt.subplot(nrows,ncols,i+1)\n    \n        # Plot the PSD for each class\n        for cl in trials.keys():\n            plt.plot(freqs, np.mean(trials_PSD[cl][ch,:,:], axis=1), label=cl)\n    \n                \n        if maxy != None:\n            plt.ylim(0,maxy)\n    \n        plt.grid()\n    \n        plt.xlabel('Frequency (Hz)')\n        \n        if chan_lab == None:\n            plt.title('Channel %d' % (ch+1))\n        else:\n            plt.title(chan_lab[i])\n\n        plt.legend()\n        \n    plt.tight_layout()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_psd(\n    trials_PSD,\n    freqs,\n    [channel_names.index(ch) for ch in ['C3', 'Cz', 'C4']],\n    chan_lab=['left', 'center', 'right'],\n    maxy=500\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bandpass(trials, lo, hi, sample_rate):\n\n    # The firwin() function takes the filter order, lower and upper frequency bounds\n    # to pass, divided by the nyquist frequency, which is the sample rate divided by 2.\n    # also provide the window function\n    fir_coeff = scipy.signal.firwin(numtaps = 6, cutoff = [lo, hi], \n                                    nyq = sample_rate/2, window = 'hamming', pass_zero = False)\n \n    # Applying the filter to each trial\n    ntrials = trials.shape[2]\n    trials_filt = np.zeros((nchannels, nsamples, ntrials))\n    for i in range(ntrials):\n        trials_filt[:,:,i] = scipy.signal.filtfilt(fir_coeff, [1], trials[:,:,i], axis=1) \n    \n    return trials_filt\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trials_filt = {cl1: bandpass(trials[cl1],5, 42, sample_rate),\n               cl2: bandpass(trials[cl2],5, 42, sample_rate)}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"psd_r, freqs = psd(trials_filt[cl1])\npsd_f, freqs = psd(trials_filt[cl2])\ntrials_PSD = {cl1: psd_r, cl2: psd_f}\n\nplot_psd(\n    trials_PSD,\n    freqs,\n    [channel_names.index(ch) for ch in ['C3', 'Cz', 'C4']],\n    chan_lab=['left', 'center', 'right'],\n    maxy=300\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"X1 = trials_filt[cl1]\nX2 = trials_filt[cl2]\nX = np.concatenate((X1, X2), axis=2)\n\n# Flatten the data from 3D (channels x samples x trials) to 2D (samples x channels*trials)\nnchannels, nsamples, ntrials = X.shape\nX = X.reshape(nsamples, nchannels*ntrials)\n\n# Create the labels for the two classes\ny1 = np.ones(100)\ny2 = np.zeros(100)\n\n# Concatenate the labels for the two classes\ny = np.concatenate((y1, y2))\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle=True)\n\nlr = LogisticRegression(solver='lbfgs')\n\n# Use k-fold cross-validation to evaluate the model\nkfold = KFold(n_splits=5)\nscores = []\ni=0\nfor train_index, val_index in kfold.split(X_train):\n    i+=1\n    X_train_fold, X_val = X_train[train_index], X_train[val_index]\n    y_train_fold, y_val = y_train[train_index], y_train[val_index]\n    lr.fit(X_train_fold, y_train_fold)\n    y_pred_test = lr.predict(X_test)\n    y_pred = lr.predict(X_val)\n    acc = accuracy_score(y_val, y_pred)\n    acc2=accuracy_score(y_test, y_pred_test)\n    print('K= ',i,'val set accuracy:', acc, '  ,test set accuracy:', acc2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X1 = trials[cl1]\nX2 = trials[cl2]\nX = np.concatenate((X1, X2), axis=2)\n\n# Flatten the data from 3D (channels x samples x trials) to 2D (samples x channels*trials)\nnchannels, nsamples, ntrials = X.shape\nX = X.reshape(nsamples, nchannels*ntrials)\n\n# Create the labels for the two classes\ny1 = np.ones(100)\ny2 = np.zeros(100)\n\n# Concatenate the labels for the two classes\ny = np.concatenate((y1, y2))\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,shuffle=True)\n\nlr = LogisticRegression(solver='lbfgs')\n\n# Use k-fold cross-validation to evaluate the model\nkfold = KFold(n_splits=5)\nscores = []\ni=0\nfor train_index, val_index in kfold.split(X_train):\n    i+=1\n    X_train_fold, X_val = X_train[train_index], X_train[val_index]\n    y_train_fold, y_val = y_train[train_index], y_train[val_index]\n    lr.fit(X_train_fold, y_train_fold)\n    y_pred_test = lr.predict(X_test)\n    y_pred = lr.predict(X_val)\n    acc = accuracy_score(y_val, y_pred)\n    acc2=accuracy_score(y_test, y_pred_test)\n    print('K= ',i,'val set accuracy:', acc, '  ,test set accuracy:', acc2)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}